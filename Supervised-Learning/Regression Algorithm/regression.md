Regression Algorithms 

Regression algorithm are varied and are used in statistics or machine learning.
Each algorithm is suitable based on the problem to be handled and the nature of the data

Types:

1. Linear Regression
Predicts a continuous outcome based on linear relationships.

Example: Predicting house prices based on size.

2. Multiple Linear Regression
Like linear regression, but uses multiple input features.

Example: Predicting salary based on education, experience, and age.

3. Polynomial Regression
Models nonlinear relationships by fitting a polynomial equation.

Example: Modeling population growth that accelerates over time.

4. Ridge Regression
A regularized version of linear regression that penalizes large coefficients (L2 regularization).

Helps prevent overfitting.

5. Lasso Regression
Similar to ridge but uses L1 regularization — can shrink coefficients to zero (feature selection).

6. Elastic Net Regression
A combination of Lasso and Ridge, balancing L1 and L2 regularization.

7. Logistic Regression
Used for classification, not continuous prediction.

Despite the name, it’s a classification method (e.g., spam vs. not spam).

8. Stepwise Regression
Automatically selects relevant variables by adding or removing them based on statistical significance.

9. Quantile Regression
Estimates conditional quantiles (e.g., median) instead of the mean.

10. Support Vector Regression (SVR)
Uses support vector machines for regression tasks — effective for nonlinear data.


